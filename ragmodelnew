"""
pip install langchain
pip install chromadb
pip install PyPDFLoader
pip install ollama
pip install sentence-transformers
pip install pandas 
"""
from langchain.document_loaders import DirectoryLoader
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_community.llms import Ollama
from langchain.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate 
from dotenv import load_dotenv
import os
import shutil
import chromadb
import ollama

""" 
This was not working because the wrong library was being used to load the file(s). Directory should always be used. 
However, if you use a "for" loop, it should work.
DATA_PATH = "C:\Anika Singh\Glenforest Secondary School\Grade 10 MYP5\Personal Project\Documents\.venv\data"
loader = PyPDFDLoader(DATA_PATH)
documents = loader.load()
print(len(documents))
print(documents)
"""

# Setting up API Key - Located in: C:\Users\nsaro\.ollama\id_ed25519.pub
load_dotenv()
OLLAMA_API_KEY = os.getenv("ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMUCpZI661uxUouUm1eGc6q75cM7HfO/YekLEo7qXqaL")

llm = Ollama(model="llama3", temperature = 0.7)

# Running a test to see if the LLM model (llama3) works
response = llm.invoke("Tell me a cat joke.")
print(response) 

# Loading my documents and printing the length of it as a test
DATA_PATH = "C:\Anika Singh\Glenforest Secondary School\Grade 10 MYP5\Personal Project\Documents\.venv\data"
loader = PyPDFDirectoryLoader(DATA_PATH)
documents = loader.load()
print(f"The length of the document is {len(documents)}")

# Splitting the PDF(s) into chunks of text 
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,
    chunk_overlap=100,
    length_function=len,
    add_start_index=True,
)
chunks = text_splitter.split_documents(documents)
print(f"Split {len(documents)} documents into {len(chunks)} chunks.")

"""
Testing the print out of my chunks 

print(chunks[0])
print()
print(chunks[1])
print() 
print(chunks[50])
"""

# Creating ChromaDB for chunkings and embeddings 
embeddings = ollama.embeddings
persistent_client = chromadb.PersistentClient()
collection = persistent_client.get_or_create_collection("collection_name")
collection.add(ids="1", documents = DATA_PATH)

vector_store_from_client = Chroma(
    client=persistent_client,
    collection_name="collection_name",
    embedding_function=embeddings,
)

# Using the Ollama embedding model 
ollama.embeddings(
  model='mxbai-embed-large'
)

def embeddings(chunks): 
    embeddings = ollama.embed(model='mxbai-embed-large', input=chunks)
    return embeddings.get('embeddings', [])